{"text_description": "Output tensor's value at ('_ML_DAIKON_RESPONSE_LENGTHS', 0) is consistently less than or equal to the max input threshold max_new_tokens for the function transformers.models.whisper.modeling_whisper.WhisperForConditionalGeneration.generate.", "relation": "ThresholdRelation", "params": [{"param_type": "InputOutputParam", "name": "max_new_tokens", "index": null, "type": "<class 'int'>", "additional_path": null, "api_name": "transformers.models.whisper.modeling_whisper.WhisperForConditionalGeneration.generate", "is_input": true}, {"param_type": "APIParam", "api_full_name": "transformers.models.whisper.modeling_whisper.WhisperForConditionalGeneration.generate"}, {"param_type": "InputOutputParam", "name": "output_tensors", "index": 0, "type": "torch.Tensor", "additional_path": ["_ML_DAIKON_RESPONSE_LENGTHS", 0], "api_name": "transformers.models.whisper.modeling_whisper.WhisperForConditionalGeneration.generate", "is_input": false}], "precondition": {"pre_event": {"inverted": false, "preconditions": [{"clauses": "Unconditional"}]}}, "num_positive_examples": null, "num_negative_examples": null}
